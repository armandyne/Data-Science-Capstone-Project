---
title: "Task 1 - Getting and Cleaning Data"
author: "Arman Iskaliyev"
date: "April 12, 2018"
output: 
  html_document: 
    keep_md: yes
    theme: spacelab
---
```{r}
suppressPackageStartupMessages(library(tidyverse))

source("./Data acquisition.R")
```

##Tasks to accomplish

1. Tokenization - identifying appropriate tokens such as words, punctuation, and numbers. Writing a function that takes a file as input and returns a tokenized version of it.

2. Profanity filtering - removing profanity and other words you do not want to predict.
